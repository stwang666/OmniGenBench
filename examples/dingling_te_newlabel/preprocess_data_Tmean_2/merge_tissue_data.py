# -*- coding: utf-8 -*-
# file: merge_tissue_data.py
# time: 10:00 22/10/2025
# author: Merge script for 9 tissue CSV files
# åˆå¹¶9ä¸ªtissueçš„CSVæ–‡ä»¶åˆ°ä¸€ä¸ªæ–‡ä»¶

import pandas as pd
import numpy as np
from pathlib import Path
import argparse
from collections import defaultdict


def read_tissue_data(file_path, tissue_name):
    """
    è¯»å–å•ä¸ªtissueçš„CSVæ–‡ä»¶
    
    å‚æ•°:
        file_path: CSVæ–‡ä»¶è·¯å¾„
        tissue_name: tissueåç§°
    
    è¿”å›:
        DataFrame with ID, Seq, label columns
    """
    print(f"ğŸ“– è¯»å– {tissue_name}_TE.csv...")
    
    try:
        df = pd.read_csv(file_path)
        
        # æ£€æŸ¥å¿…éœ€çš„åˆ—
        if 'ID' not in df.columns:
            print(f"   âŒ é”™è¯¯: æ–‡ä»¶ä¸­æ²¡æœ‰'ID'åˆ—")
            return None
        
        if 'Seq' not in df.columns:
            print(f"   âŒ é”™è¯¯: æ–‡ä»¶ä¸­æ²¡æœ‰'Seq'åˆ—")
            return None
            
        if 'label' not in df.columns:
            print(f"   âŒ é”™è¯¯: æ–‡ä»¶ä¸­æ²¡æœ‰'label'åˆ—")
            return None
        
        # åªä¿ç•™éœ€è¦çš„åˆ—
        tissue_df = df[['ID', 'Seq', 'label']].copy()
        
        # é‡å‘½ålabelåˆ—ä¸ºtissueç‰¹å®šçš„åç§°
        tissue_df.rename(columns={'label': f'{tissue_name}_TE_label'}, inplace=True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_samples = len(tissue_df)
        label_counts = tissue_df[f'{tissue_name}_TE_label'].value_counts(dropna=False)
        
        print(f"   âœ… è¯»å– {total_samples} ä¸ªæ ·æœ¬")
        print(f"   æ ‡ç­¾åˆ†å¸ƒ:")
        for label, count in label_counts.items():
            if pd.isna(label):
                print(f"      NA: {count}")
            else:
                print(f"      {label}: {count}")
        
        return tissue_df
        
    except Exception as e:
        print(f"   âŒ è¯»å–å¤±è´¥: {e}")
        return None


def merge_tissue_dataframes(tissue_dfs, tissue_names):
    """
    åˆå¹¶å¤šä¸ªtissueçš„DataFrame
    
    å‚æ•°:
        tissue_dfs: tissue DataFrameåˆ—è¡¨
        tissue_names: tissueåç§°åˆ—è¡¨
    
    è¿”å›:
        åˆå¹¶åçš„DataFrame
    """
    print(f"\nğŸ”— å¼€å§‹åˆå¹¶æ•°æ®...")
    
    if not tissue_dfs:
        print("âŒ æ²¡æœ‰æ•°æ®å¯ä»¥åˆå¹¶")
        return None
    
    # ä»ç¬¬ä¸€ä¸ªDataFrameå¼€å§‹
    merged_df = tissue_dfs[0].copy()
    print(f"   åŸºç¡€æ•°æ®: {tissue_names[0]} ({len(merged_df)} ä¸ªæ ·æœ¬)")
    
    # ä¾æ¬¡åˆå¹¶å…¶ä»–DataFrame
    for i, (df, tissue_name) in enumerate(zip(tissue_dfs[1:], tissue_names[1:]), 1):
        print(f"   åˆå¹¶ {tissue_name}...")
        
        # ä½¿ç”¨outer joinä¿ç•™æ‰€æœ‰ID
        before_count = len(merged_df)
        merged_df = pd.merge(
            merged_df,
            df,
            on=['ID', 'Seq'],
            how='outer',
            suffixes=('', f'_{tissue_name}')
        )
        after_count = len(merged_df)
        
        if after_count > before_count:
            print(f"      æ–°å¢ {after_count - before_count} ä¸ªæ ·æœ¬")
    
    print(f"   âœ… åˆå¹¶å®Œæˆï¼Œæ€»å…± {len(merged_df)} ä¸ªæ ·æœ¬")
    
    return merged_df


def check_sequence_consistency(merged_df):
    """
    æ£€æŸ¥IDç›¸åŒçš„æ ·æœ¬æ˜¯å¦æœ‰ä¸åŒçš„åºåˆ—
    
    å‚æ•°:
        merged_df: åˆå¹¶åçš„DataFrame
    """
    print(f"\nğŸ” æ£€æŸ¥åºåˆ—ä¸€è‡´æ€§...")
    
    # æŒ‰IDåˆ†ç»„ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªä¸åŒçš„åºåˆ—
    grouped = merged_df.groupby('ID')['Seq'].nunique()
    inconsistent_ids = grouped[grouped > 1]
    
    if len(inconsistent_ids) > 0:
        print(f"   âš ï¸  è­¦å‘Š: å‘ç° {len(inconsistent_ids)} ä¸ªIDæœ‰ä¸åŒçš„åºåˆ—")
        print(f"   ç¤ºä¾‹ (å‰5ä¸ª):")
        for id_name in inconsistent_ids.head(5).index:
            seqs = merged_df[merged_df['ID'] == id_name]['Seq'].unique()
            print(f"      {id_name}: {len(seqs)} ä¸ªä¸åŒåºåˆ—")
    else:
        print(f"   âœ… æ‰€æœ‰IDçš„åºåˆ—ä¸€è‡´")


def generate_statistics(merged_df, tissue_names):
    """
    ç”Ÿæˆæ•°æ®ç»Ÿè®¡æŠ¥å‘Š
    
    å‚æ•°:
        merged_df: åˆå¹¶åçš„DataFrame
        tissue_names: tissueåç§°åˆ—è¡¨
    """
    print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡æŠ¥å‘Š")
    print("=" * 60)
    
    # æ€»ä½“ç»Ÿè®¡
    print(f"\næ€»æ ·æœ¬æ•°: {len(merged_df)}")
    
    # æ¯ä¸ªtissueçš„æ ‡ç­¾ç»Ÿè®¡
    print(f"\nå„tissueæ ‡ç­¾åˆ†å¸ƒ:")
    for tissue in tissue_names:
        label_col = f'{tissue}_TE_label'
        if label_col in merged_df.columns:
            total = len(merged_df)
            non_na = merged_df[label_col].notna().sum()
            label_0 = (merged_df[label_col] == 0).sum()
            label_1 = (merged_df[label_col] == 1).sum()
            na_count = merged_df[label_col].isna().sum()
            
            print(f"\n{tissue:25s}:")
            print(f"   æœ‰æ•ˆæ ‡ç­¾: {non_na}/{total} ({non_na/total*100:.1f}%)")
            print(f"   æ ‡ç­¾=0: {label_0} ({label_0/total*100:.1f}%)")
            print(f"   æ ‡ç­¾=1: {label_1} ({label_1/total*100:.1f}%)")
            print(f"   æ ‡ç­¾=NA: {na_count} ({na_count/total*100:.1f}%)")
    
    # æ¯ä¸ªæ ·æœ¬æœ‰å¤šå°‘ä¸ªtissueæœ‰æ ‡ç­¾
    label_cols = [f'{tissue}_TE_label' for tissue in tissue_names if f'{tissue}_TE_label' in merged_df.columns]
    merged_df['num_tissues_with_label'] = merged_df[label_cols].notna().sum(axis=1)
    
    print(f"\næ¯ä¸ªæ ·æœ¬çš„tissueæ ‡ç­¾æ•°é‡åˆ†å¸ƒ:")
    label_count_dist = merged_df['num_tissues_with_label'].value_counts().sort_index()
    for num_labels, count in label_count_dist.items():
        print(f"   {int(num_labels)} ä¸ªtissue: {count} ä¸ªæ ·æœ¬ ({count/len(merged_df)*100:.1f}%)")
    
    # åˆ é™¤ä¸´æ—¶åˆ—
    merged_df.drop('num_tissues_with_label', axis=1, inplace=True)


def merge_tissue_files(data_dir, output_file=None, generate_report=True):
    """
    åˆå¹¶9ä¸ªtissueçš„CSVæ–‡ä»¶
    
    å‚æ•°:
        data_dir: åŒ…å«9ä¸ªtissue CSVæ–‡ä»¶çš„ç›®å½•
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ä¸ºdata_dir/merged_tissue_data.csvï¼‰
        generate_report: æ˜¯å¦ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    
    è¿”å›:
        åˆå¹¶åçš„DataFrame
    """
    data_dir = Path(data_dir)
    
    # 9ä¸ªtissueçš„åç§°ï¼ˆæŒ‰ç…§æŒ‡å®šé¡ºåºï¼‰
    tissue_names = [
        'root', 'seedling', 'leaf', 'FMI', 'FOD',
        'Prophase-I-pollen', 'Tricellular-pollen', 'flag', 'grain'
    ]
    
    print("=" * 60)
    print("åˆå¹¶9ä¸ªTissueæ•°æ®æ–‡ä»¶")
    print("=" * 60)
    print(f"\nğŸ“ æ•°æ®ç›®å½•: {data_dir}")
    
    # è¯»å–æ‰€æœ‰tissueæ•°æ®
    tissue_dfs = []
    successful_tissues = []
    
    for tissue in tissue_names:
        csv_file = data_dir / f"{tissue}_TE.csv"
        
        if not csv_file.exists():
            print(f"\nâš ï¸  è­¦å‘Š: æ‰¾ä¸åˆ°æ–‡ä»¶ {csv_file}")
            continue
        
        df = read_tissue_data(csv_file, tissue)
        
        if df is not None:
            tissue_dfs.append(df)
            successful_tissues.append(tissue)
    
    if not tissue_dfs:
        print("\nâŒ é”™è¯¯: æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•tissueæ•°æ®")
        return None
    
    # åˆå¹¶æ•°æ®
    merged_df = merge_tissue_dataframes(tissue_dfs, successful_tissues)
    
    if merged_df is None:
        return None
    
    # æ£€æŸ¥åºåˆ—ä¸€è‡´æ€§
    check_sequence_consistency(merged_df)
    
    # ç¡®ä¿åˆ—çš„é¡ºåºæ­£ç¡®
    label_cols = [f'{tissue}_TE_label' for tissue in tissue_names if f'{tissue}_TE_label' in merged_df.columns]
    column_order = ['ID', 'Seq'] + label_cols
    
    # é‡å‘½åSeqä¸ºsequenceï¼ˆæ›´ç»Ÿä¸€ï¼‰
    merged_df.rename(columns={'Seq': 'sequence'}, inplace=True)
    column_order = ['ID', 'sequence'] + label_cols
    
    # åªä¿ç•™æŒ‡å®šçš„åˆ—
    merged_df = merged_df[column_order]
    
    # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    if generate_report:
        generate_statistics(merged_df, successful_tissues)
    
    # ä¿å­˜æ–‡ä»¶
    if output_file is None:
        output_file = data_dir / "merged_tissue_data.csv"
    else:
        output_file = Path(output_file)
    
    print(f"\nğŸ’¾ ä¿å­˜åˆå¹¶åçš„æ•°æ®...")
    merged_df.to_csv(output_file, index=False)
    print(f"   âœ… å·²ä¿å­˜åˆ°: {output_file}")
    print(f"   æ–‡ä»¶å¤§å°: {output_file.stat().st_size / 1024 / 1024:.1f} MB")
    
    # ä¿å­˜ç»Ÿè®¡æŠ¥å‘Šåˆ°æ–‡æœ¬æ–‡ä»¶
    if generate_report:
        report_file = output_file.parent / "merge_report.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("åˆå¹¶9ä¸ªTissueæ•°æ®æ–‡ä»¶ - ç»Ÿè®¡æŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            f.write(f"æ€»æ ·æœ¬æ•°: {len(merged_df)}\n")
            f.write(f"è¾“å‡ºæ–‡ä»¶: {output_file}\n")
            f.write(f"\næˆåŠŸåˆå¹¶çš„tissue: {', '.join(successful_tissues)}\n")
            
            # å„tissueæ ‡ç­¾ç»Ÿè®¡
            f.write(f"\nå„tissueæ ‡ç­¾åˆ†å¸ƒ:\n")
            for tissue in successful_tissues:
                label_col = f'{tissue}_TE_label'
                if label_col in merged_df.columns:
                    total = len(merged_df)
                    non_na = merged_df[label_col].notna().sum()
                    label_0 = (merged_df[label_col] == 0).sum()
                    label_1 = (merged_df[label_col] == 1).sum()
                    na_count = merged_df[label_col].isna().sum()
                    
                    f.write(f"\n{tissue}:\n")
                    f.write(f"  æœ‰æ•ˆæ ‡ç­¾: {non_na}/{total} ({non_na/total*100:.1f}%)\n")
                    f.write(f"  æ ‡ç­¾=0: {label_0} ({label_0/total*100:.1f}%)\n")
                    f.write(f"  æ ‡ç­¾=1: {label_1} ({label_1/total*100:.1f}%)\n")
                    f.write(f"  æ ‡ç­¾=NA: {na_count} ({na_count/total*100:.1f}%)\n")
        
        print(f"   âœ… ç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    
    print("\nğŸ‰ åˆå¹¶å®Œæˆï¼")
    
    return merged_df


def main():
    parser = argparse.ArgumentParser(description='åˆå¹¶9ä¸ªtissueçš„CSVæ–‡ä»¶')
    parser.add_argument('--data_dir', type=str, required=True,
                        help='åŒ…å«9ä¸ªtissue CSVæ–‡ä»¶çš„ç›®å½•')
    parser.add_argument('--output', type=str, default=None,
                        help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ä¸ºdata_dir/merged_tissue_data.csvï¼‰')
    parser.add_argument('--no_report', action='store_true',
                        help='ä¸ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š')
    
    args = parser.parse_args()
    
    merge_tissue_files(
        data_dir=args.data_dir,
        output_file=args.output,
        generate_report=not args.no_report
    )


if __name__ == '__main__':
    main()

