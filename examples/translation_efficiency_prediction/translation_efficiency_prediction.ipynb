{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d03d47b62530a46",
   "metadata": {},
   "source": [
    "# Translation Efficiency Prediction with OmniGenBench\n",
    "\n",
    "This notebook demonstrates how to fine-tune a Genomic Foundation Model (GFM) to predict Rice translation efficiency (TE) from mRNA sequences using OmniGenBench. The example focusing on plant RNA translation efficiency.\n",
    "\n",
    "**Background (PlantRNA-FM):**\n",
    "PlantRNA-FM (\"An interpretable RNA foundation model for exploring functional RNA motifs in plants\") introduces an RNA foundation model tailored to plant genomics, highlighting interpretability and motif discovery capabilities. TE prediction is a representative downstream task where models learn sequence determinants associated with efficient translation. In this demo, we use a small rice 5'UTR/mRNA TE dataset to illustrate fine-tuning and evaluation within OmniGenBench.\n",
    "\n",
    "- **Task type**: Binary sequence classification (High-TE vs Low-TE)\n",
    "- **Input**: RNA sequences (string), up to a configurable `max_length`\n",
    "- **Label space**: {0: Low-TE, 1: High-TE}\n",
    "\n",
    "**Estimated runtime:** On a single NVIDIA RTX 4090, a short training run on this toy dataset typically takes ~5–10 minutes depending on epochs/model size.\n",
    "\n",
    "## Notebook Structure\n",
    "1. **Setup & Installation**: Install optional dependencies.\n",
    "2. **Import Libraries**: Load Python packages and local utilities.\n",
    "3. **Configuration & Data**: Choose a model, set hyperparameters, and point to dataset files.\n",
    "4. **Main Analysis Pipeline**: Run training/evaluation with `utils.run_training`.\n",
    "5. **Results Overview**: Summarize validation/test metrics.\n",
    "6. **Visualization**: Plot validation metrics across epochs.\n",
    "7. **References**: Link to PlantRNA-FM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c32ddd990cf9a5",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation\n",
    "\n",
    "This section handles the initial setup, including installing necessary packages. If dependencies are already available, you can skip the installation cell.\n",
    "\n",
    "### 1.1. Install Dependencies\n",
    "Uncomment and run the following cell to install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7764a9ae022a177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: install dependencies if not available\n",
    "# !pip install torch transformers pandas autocuda multimolecule biopython scipy scikit-learn tqdm dill findfile requests omnigenbench\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95cc32df65efce2",
   "metadata": {},
   "source": [
    "## 2. Import Libraries\n",
    "Import all necessary libraries for data processing, model training, and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40711471de59eadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import autocuda\n",
    "\n",
    "# Import utilities from the local utils.py file\n",
    "utils_spec = importlib.util.spec_from_file_location(\"utils\", \"utils.py\")\n",
    "utils = importlib.util.module_from_spec(utils_spec)\n",
    "utils_spec.loader.exec_module(utils)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cc7e2a6a9bbf4f",
   "metadata": {},
   "source": [
    "## 3. Configuration & Data\n",
    "\n",
    "Set up the analysis parameters, file paths, and model selection here. You can easily change the `MODEL_NAME` to test different GFMs.\n",
    "\n",
    "### 3.1. Model Selection\n",
    "Choose the Genomic Foundation Model to fine-tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8fa66f66a945e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using utils for reusable logic\n",
    "from utils import run_training\n",
    "print(\"Core classes and functions imported from utils.\")\n",
    "\n",
    "# --- Available Models for Testing ---\n",
    "AVAILABLE_MODELS = [\n",
    "    'yangheng/OmniGenome-52M',\n",
    "    'yangheng/OmniGenome-186M',\n",
    "    'yangheng/OmniGenome-v1.5',\n",
    "]\n",
    "MODEL_NAME = AVAILABLE_MODELS[0]  # Model to use for predictions\n",
    "print(f\"Selected model: {MODEL_NAME}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f4004907ee25be",
   "metadata": {},
   "source": [
    "### 3.2. Hyperparameter and Dataset Configuration\n",
    "Define the training hyperparameters and paths to the dataset files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2934768104a4c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Hyperparameters ---\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 2e-5\n",
    "WEIGHT_DECAY = 1e-5\n",
    "BATCH_SIZE = 4\n",
    "MAX_LENGTH = 1024\n",
    "SEED = 42\n",
    "\n",
    "# --- Dataset Configuration ---\n",
    "TRAIN_FILE = \"te_rice_dataset/train.json\"\n",
    "VALID_FILE = \"te_rice_dataset/valid.json\"  # validation split\n",
    "TEST_FILE = \"te_rice_dataset/test.json\"    # test split\n",
    "\n",
    "# --- Label Mapping ---\n",
    "# The task is binary classification: 1 for TE, 0 for non-TE.\n",
    "LABEL2ID = {\"0\": 0, \"1\": 1}\n",
    "\n",
    "print(f\"Selected model: {MODEL_NAME}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb46abec3b21caef",
   "metadata": {},
   "source": [
    "## 4. Main Analysis Pipeline\n",
    "\n",
    "This section executes the training/evaluation pipeline using the configuration defined above. The `run_training` function from `examples/translation_efficiency_prediction/utils.py` orchestrates tokenization, dataset creation, training, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364efdcfe00fab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import main pipeline from utils for a concise demo\n",
    "from utils import run_training\n",
    "\n",
    "print(\"Main analysis pipeline imported from utils.\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Run the analysis\n",
    "metrics = run_training(\n",
    "\tmodel_name=MODEL_NAME,\n",
    "\ttrain_file=TRAIN_FILE,\n",
    "\tvalid_file=VALID_FILE,\n",
    "\ttest_file=TEST_FILE,\n",
    "\tlabel2id=LABEL2ID,\n",
    "\tepochs=EPOCHS,\n",
    "\tlearning_rate=LEARNING_RATE,\n",
    "\tweight_decay=WEIGHT_DECAY,\n",
    "\tbatch_size=BATCH_SIZE,\n",
    "\tmax_length=MAX_LENGTH,\n",
    "\tseed=SEED,\n",
    ")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Analysis completed!\")\n",
    "\n",
    "# Print final validation and test metrics (if available)\n",
    "if metrics.get('valid'):\n",
    "\tprint(\"\\nValidation Set Performance (last epoch):\")\n",
    "\tfor key, value in metrics['valid'][-1].items():\n",
    "\t\tprint(f\"{key}: {value:.4f}\")\n",
    "\n",
    "if metrics.get('test'):\n",
    "\tprint(\"\\nTest Set Performance (best checkpoint):\")\n",
    "\tfor key, value in metrics['test'][-1].items():\n",
    "\t\tprint(f\"{key}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9136c2be",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b624ae7",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259595d83567be5b",
   "metadata": {},
   "source": [
    "## 5. Results Overview\n",
    "\n",
    "We display the last-epoch validation metrics and the final test metrics (evaluated using the best checkpoint selected by validation performance). This mirrors the concise reporting style used in the VEP notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d99fa6",
   "metadata": {},
   "source": [
    "## 6. Visualization\n",
    "\n",
    "In this section, we visualize validation metrics across epochs to assess learning dynamics.\n",
    "\n",
    "### 6.1. Plot Validation Curves\n",
    "We plot macro F1 across epochs. Additional metrics (e.g., MCC) can be added if enabled in `utils.py` or dataset config.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Results Overview — Quick summary of metrics\n",
    "if metrics.get('valid'):\n",
    "\tprint('Validation (last epoch):')\n",
    "\tfor k, v in metrics['valid'][-1].items():\n",
    "\t\tprint(f\"{k}: {v:.4f}\")\n",
    "\n",
    "if metrics.get('test'):\n",
    "\tprint('\\nTest (best checkpoint):')\n",
    "\tfor k, v in metrics['test'][-1].items():\n",
    "\t\tprint(f\"{k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545cc699d0f197f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Visualization — Plot validation curve\n",
    "valid_key = 'valid' if 'valid' in metrics else ('eval' if 'eval' in metrics else None)\n",
    "if valid_key is None:\n",
    "\tprint(\"No validation metrics found for plotting.\")\n",
    "else:\n",
    "\tvalid_df = pd.DataFrame(metrics[valid_key])\n",
    "\tplt.style.use('seaborn-v0_8-whitegrid')\n",
    "\tfig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "\tif 'f1_score' in valid_df.columns:\n",
    "\t\tsns.lineplot(data=valid_df, x=valid_df.index, y='f1_score', ax=ax, label='Validation F1 (Macro)')\n",
    "\t\tax.set_ylabel('F1 Score')\n",
    "\telif 'matthews_corrcoef' in valid_df.columns:\n",
    "\t\tsns.lineplot(data=valid_df, x=valid_df.index, y='matthews_corrcoef', ax=ax, label='Validation MCC')\n",
    "\t\tax.set_ylabel('MCC')\n",
    "\telse:\n",
    "\t\tfirst_col = [c for c in valid_df.columns if isinstance(valid_df[c].iloc[-1], (int, float))]\n",
    "\t\tif first_col:\n",
    "\t\t\tsns.lineplot(data=valid_df, x=valid_df.index, y=first_col[0], ax=ax, label=first_col[0])\n",
    "\t\t\tax.set_ylabel(first_col[0])\n",
    "\t\telse:\n",
    "\t\t\tprint(\"Validation metrics exist but no numeric columns to plot.\")\n",
    "\tax.set_title('Validation Metric across Epochs')\n",
    "\tax.set_xlabel('Epoch')\n",
    "\tax.legend()\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5423a802",
   "metadata": {},
   "source": [
    "## 7. References\n",
    "\n",
    "- PlantRNA-FM: \"An interpretable RNA foundation model for exploring functional RNA motifs in plants\" (Nature Machine Intelligence, 2024).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
