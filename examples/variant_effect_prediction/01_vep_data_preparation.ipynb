{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db9ca148",
   "metadata": {},
   "source": [
    "# üìä VEP Data Preparation Tutorial\n",
    "\n",
    "This tutorial focuses on data preparation for Variant Effect Prediction (VEP) analysis using OmniGenBench's enhanced dataset loading capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8941ae97",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2571a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from omnigenbench import (\n",
    "    OmniTokenizer,\n",
    "    OmniDatasetForSequenceClassification\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186d1a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VEP Data Configuration\n",
    "class VEPDataConfig:\n",
    "    DATASET_NAME = \"yangheng/variant_effect_prediction\"\n",
    "    MODEL_NAME = \"yangheng/OmniGenome-52M\"\n",
    "    CACHE_DIR = \"vep_data_cache\"\n",
    "    MAX_LENGTH = 512\n",
    "    \n",
    "    # Quick testing parameters\n",
    "    SAMPLE_SIZE = 100  # Use subset for quick analysis\n",
    "\n",
    "config = VEPDataConfig()\n",
    "print(\"‚öôÔ∏è Configuration set for VEP data preparation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20699271",
   "metadata": {},
   "source": [
    "## 2. Enhanced Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad78341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "print(\"üîÑ Loading tokenizer...\")\n",
    "tokenizer = OmniTokenizer.from_pretrained(config.MODEL_NAME, trust_remote_code=True)\n",
    "\n",
    "# Load VEP dataset using enhanced OmniDataset\n",
    "print(\"üìä Loading VEP dataset with automatic caching...\")\n",
    "datasets = OmniDatasetForSequenceClassification.from_huggingface(\n",
    "    dataset_name=config.DATASET_NAME,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=config.MAX_LENGTH,\n",
    "    cache_dir=config.CACHE_DIR\n",
    ")\n",
    "\n",
    "print(f\"üìã VEP Dataset loaded:\")\n",
    "for split, dataset in datasets.items():\n",
    "    print(f\"  üìä {split.title()}: {len(dataset)} variants\")\n",
    "\n",
    "print(\"‚úÖ Data preparation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c51c99c",
   "metadata": {},
   "source": [
    "## 3. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952fb83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore dataset structure\n",
    "test_dataset = datasets['test']\n",
    "sample_item = test_dataset[0]\n",
    "\n",
    "print(\"üîç Sample variant structure:\")\n",
    "for key, value in sample_item.items():\n",
    "    print(f\"  {key}: {type(value)} - {str(value)[:100]}...\")\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "dataloader = test_dataset.get_dataloader(batch_size=8, shuffle=False)\n",
    "sample_batch = next(iter(dataloader))\n",
    "\n",
    "print(f\"\\nüì¶ Sample batch structure:\")\n",
    "for key, tensor in sample_batch.items():\n",
    "    print(f\"  {key}: {tensor.shape}\")\n",
    "\n",
    "print(\"‚úÖ Data exploration complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
