# -*- coding: utf-8 -*-
# file: advanced_perturbation_analysis.py
# time: 10:30 19/10/2025
# author: Advanced Sequence Perturbation Analysis
# Description: Comprehensive perturbation analysis with multiple visualization options

import os
import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import random
import pandas as pd

from omnigenbench import (
    ModelHub,
    OmniTokenizer,
)

# å¯¼å…¥è‡ªå®šä¹‰çš„ Dataset ç±»
import sys
sys.path.append(os.path.dirname(__file__))
from triclass_te import TriClassTEDataset


class SequencePerturbationAnalyzer:
    """åºåˆ—æ‰°åŠ¨åˆ†æå™¨"""
    
    def __init__(self, model, tissue_names=None):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            model: è®­ç»ƒå¥½çš„æ¨¡å‹
            tissue_names: ç»„ç»‡åç§°åˆ—è¡¨
        """
        self.model = model
        self.model.eval()
        
        if tissue_names is None:
            self.tissue_names = [
                'root', 'seedling', 'leaf', 'FMI', 'FOD',
                'Prophase-I-pollen', 'Tricellular-pollen', 'flag', 'grain'
            ]
        else:
            self.tissue_names = tissue_names
        
        self.nucleotides = ['A', 'T', 'C', 'G']
        self.label_names = ['Low', 'Medium', 'High']
    
    def substitute_nucleotide(self, sequence, position, new_nucleotide=None):
        """
        åœ¨æŒ‡å®šä½ç½®æ›¿æ¢æ ¸è‹·é…¸
        
        Args:
            sequence: DNAåºåˆ—
            position: ä½ç½®ç´¢å¼•
            new_nucleotide: æ–°çš„æ ¸è‹·é…¸ï¼ˆå¦‚æœä¸ºNoneåˆ™éšæœºé€‰æ‹©ï¼‰
        
        Returns:
            æ‰°åŠ¨åçš„åºåˆ—
        """
        seq_list = list(sequence)
        original_nuc = seq_list[position].upper()
        
        if new_nucleotide is None:
            # éšæœºé€‰æ‹©ä¸€ä¸ªä¸åŒçš„æ ¸è‹·é…¸
            alternative_nucs = [n for n in self.nucleotides if n != original_nuc]
            new_nucleotide = random.choice(alternative_nucs)
        
        seq_list[position] = new_nucleotide
        return ''.join(seq_list)
    
    def delete_nucleotide(self, sequence, position):
        """åˆ é™¤æŒ‡å®šä½ç½®çš„æ ¸è‹·é…¸"""
        return sequence[:position] + sequence[position+1:]
    
    def insert_nucleotide(self, sequence, position, nucleotide=None):
        """åœ¨æŒ‡å®šä½ç½®æ’å…¥æ ¸è‹·é…¸"""
        if nucleotide is None:
            nucleotide = random.choice(self.nucleotides)
        return sequence[:position] + nucleotide + sequence[position:]
    
    def get_prediction(self, sample_data):
        """è·å–æ¨¡å‹é¢„æµ‹"""
        with torch.no_grad():
            outputs = self.model.inference(sample_data)
            predictions = outputs['predictions'].cpu().numpy()
            probabilities = outputs['probabilities'].cpu().numpy()
        return predictions, probabilities
    
    def calculate_prediction_change_score(self, original_pred, perturbed_pred, 
                                         original_probs, perturbed_probs):
        """
        è®¡ç®—é¢„æµ‹å˜åŒ–åˆ†æ•°ï¼ˆç»¼åˆè€ƒè™‘ç±»åˆ«å˜åŒ–å’Œæ¦‚ç‡å˜åŒ–ï¼‰
        
        Returns:
            change_score: å˜åŒ–åˆ†æ•°
            category_change: ç±»åˆ«å˜åŒ–æ•°é‡
            prob_change: æ¦‚ç‡å˜åŒ–å¹…åº¦
        """
        # ç±»åˆ«å˜åŒ–
        category_change = (original_pred != perturbed_pred).sum()
        
        # æ¦‚ç‡å˜åŒ–ï¼ˆKLæ•£åº¦ï¼‰
        prob_change = 0
        for i in range(len(original_pred)):
            # é¿å…log(0)
            eps = 1e-10
            orig_p = original_probs[i] + eps
            pert_p = perturbed_probs[i] + eps
            # KLæ•£åº¦
            kl_div = np.sum(orig_p * np.log(orig_p / pert_p))
            prob_change += kl_div
        
        prob_change /= len(original_pred)
        
        # ç»¼åˆåˆ†æ•°ï¼ˆç±»åˆ«å˜åŒ–æƒé‡æ›´é«˜ï¼‰
        change_score = 0.7 * (category_change / len(original_pred)) + 0.3 * prob_change
        
        return change_score, category_change, prob_change
    
    def analyze_position_importance(self, sequence, sample_data, 
                                   position, num_perturbations=10,
                                   perturbation_type='substitution'):
        """
        åˆ†æå•ä¸ªä½ç½®çš„é‡è¦æ€§
        
        Args:
            sequence: è¾“å…¥åºåˆ—
            sample_data: æ ·æœ¬æ•°æ®
            position: è¦åˆ†æçš„ä½ç½®
            num_perturbations: æ‰°åŠ¨æ¬¡æ•°
            perturbation_type: æ‰°åŠ¨ç±»å‹ ('substitution', 'deletion', 'insertion')
        
        Returns:
            importance_metrics: é‡è¦æ€§æŒ‡æ ‡å­—å…¸
        """
        # è·å–åŸå§‹é¢„æµ‹
        original_pred, original_probs = self.get_prediction(sample_data)
        
        change_scores = []
        category_changes = []
        prob_changes = []
        tissue_changes = np.zeros(len(self.tissue_names))
        
        for _ in range(num_perturbations):
            # ç”Ÿæˆæ‰°åŠ¨åºåˆ—
            if perturbation_type == 'substitution':
                perturbed_seq = self.substitute_nucleotide(sequence, position)
            elif perturbation_type == 'deletion':
                perturbed_seq = self.delete_nucleotide(sequence, position)
            elif perturbation_type == 'insertion':
                perturbed_seq = self.insert_nucleotide(sequence, position)
            else:
                raise ValueError(f"Unknown perturbation type: {perturbation_type}")
            
            # åˆ›å»ºæ‰°åŠ¨æ ·æœ¬
            perturbed_data = sample_data.copy()
            perturbed_data['sequence'] = perturbed_seq
            
            # è·å–æ‰°åŠ¨åçš„é¢„æµ‹
            perturbed_pred, perturbed_probs = self.get_prediction(perturbed_data)
            
            # è®¡ç®—å˜åŒ–
            change_score, cat_change, prob_change = self.calculate_prediction_change_score(
                original_pred, perturbed_pred, original_probs, perturbed_probs
            )
            
            change_scores.append(change_score)
            category_changes.append(cat_change)
            prob_changes.append(prob_change)
            
            # è®°å½•æ¯ä¸ªç»„ç»‡çš„å˜åŒ–
            for tissue_idx in range(len(self.tissue_names)):
                if original_pred[tissue_idx] != perturbed_pred[tissue_idx]:
                    tissue_changes[tissue_idx] += 1
        
        importance_metrics = {
            'change_score': np.mean(change_scores),
            'change_score_std': np.std(change_scores),
            'category_change': np.mean(category_changes),
            'prob_change': np.mean(prob_changes),
            'tissue_changes': tissue_changes / num_perturbations,
        }
        
        return importance_metrics
    
    def analyze_full_sequence(self, sequence, sample_data, 
                             step_size=10, num_perturbations=5,
                             perturbation_type='substitution'):
        """
        åˆ†ææ•´ä¸ªåºåˆ—çš„é‡è¦æ€§
        
        Args:
            sequence: è¾“å…¥åºåˆ—
            sample_data: æ ·æœ¬æ•°æ®
            step_size: é‡‡æ ·æ­¥é•¿
            num_perturbations: æ¯ä¸ªä½ç½®çš„æ‰°åŠ¨æ¬¡æ•°
            perturbation_type: æ‰°åŠ¨ç±»å‹
        
        Returns:
            results: åˆ†æç»“æœå­—å…¸
        """
        seq_length = len(sequence)
        positions_to_test = range(0, seq_length, step_size)
        
        print(f"\nğŸ”¬ Analyzing sequence with {len(list(positions_to_test))} positions...")
        
        # åˆå§‹åŒ–ç»“æœæ•°ç»„
        importance_scores = np.zeros(seq_length)
        position_tissue_importance = np.zeros((seq_length, len(self.tissue_names)))
        
        for pos in tqdm(positions_to_test, desc="Analyzing positions"):
            metrics = self.analyze_position_importance(
                sequence, sample_data, pos, 
                num_perturbations=num_perturbations,
                perturbation_type=perturbation_type
            )
            
            # å¡«å……åˆ°æ­¥é•¿å†…çš„æ‰€æœ‰ä½ç½®
            start_pos = pos
            end_pos = min(pos + step_size, seq_length)
            for p in range(start_pos, end_pos):
                importance_scores[p] = metrics['change_score']
                position_tissue_importance[p] = metrics['tissue_changes']
        
        results = {
            'importance_scores': importance_scores,
            'position_tissue_importance': position_tissue_importance,
            'sequence': sequence,
            'sample_data': sample_data,
        }
        
        return results
    
    def plot_comprehensive_analysis(self, results, sample_id="sample", 
                                   save_dir=None, show_top_k=20):
        """
        ç»˜åˆ¶ç»¼åˆåˆ†æå›¾
        
        Args:
            results: åˆ†æç»“æœ
            sample_id: æ ·æœ¬ID
            save_dir: ä¿å­˜ç›®å½•
            show_top_k: æ˜¾ç¤ºå‰Kä¸ªé‡è¦ä½ç½®
        """
        importance_scores = results['importance_scores']
        position_tissue_importance = results['position_tissue_importance']
        sequence = results['sequence']
        
        seq_length = len(sequence)
        positions = np.arange(seq_length)
        
        # åˆ›å»ºå¤§å‹ç»¼åˆå›¾
        fig = plt.figure(figsize=(24, 16))
        gs = fig.add_gridspec(4, 2, hspace=0.3, wspace=0.3)
        
        # 1. æ€»ä½“é‡è¦æ€§æ¡å½¢å›¾ï¼ˆå¸¦æ ¸è‹·é…¸é¢œè‰²ï¼‰
        ax1 = fig.add_subplot(gs[0, :])
        colors = []
        nuc_color_map = {
            'A': '#FF6B6B', 'T': '#4ECDC4', 
            'C': '#45B7D1', 'G': '#FFA07A'
        }
        for nuc in sequence:
            colors.append(nuc_color_map.get(nuc.upper(), '#CCCCCC'))
        
        ax1.bar(positions, importance_scores, color=colors, alpha=0.7, 
               edgecolor='black', linewidth=0.3)
        ax1.set_xlabel('Sequence Position', fontsize=14, fontweight='bold')
        ax1.set_ylabel('Importance Score', fontsize=14, fontweight='bold')
        ax1.set_title(f'Overall Sequence Importance - {sample_id}', 
                     fontsize=16, fontweight='bold')
        ax1.grid(axis='y', alpha=0.3, linestyle='--')
        
        # æ·»åŠ å›¾ä¾‹
        from matplotlib.patches import Patch
        legend_elements = [
            Patch(facecolor='#FF6B6B', label='A'),
            Patch(facecolor='#4ECDC4', label='T'),
            Patch(facecolor='#45B7D1', label='C'),
            Patch(facecolor='#FFA07A', label='G')
        ]
        ax1.legend(handles=legend_elements, loc='upper right', ncol=4, fontsize=12)
        
        # 2. ç»„ç»‡ç‰¹å¼‚æ€§é‡è¦æ€§çƒ­åŠ›å›¾
        ax2 = fig.add_subplot(gs[1, :])
        sns.heatmap(position_tissue_importance.T, 
                   cmap='YlOrRd', 
                   cbar_kws={'label': 'Prediction Change Frequency'},
                   xticklabels=False,
                   yticklabels=self.tissue_names,
                   ax=ax2,
                   vmin=0,
                   vmax=1)
        ax2.set_xlabel('Sequence Position', fontsize=14, fontweight='bold')
        ax2.set_ylabel('Tissue Type', fontsize=14, fontweight='bold')
        ax2.set_title('Tissue-Specific Importance Heatmap', fontsize=16, fontweight='bold')
        
        # 3. Top K é‡è¦ä½ç½®è¯¦ç»†ä¿¡æ¯
        ax3 = fig.add_subplot(gs[2, 0])
        top_k_indices = np.argsort(importance_scores)[-show_top_k:][::-1]
        top_k_scores = importance_scores[top_k_indices]
        top_k_nucs = [sequence[i] for i in top_k_indices]
        
        bars = ax3.barh(range(show_top_k), top_k_scores, 
                       color=[nuc_color_map.get(n.upper(), '#CCCCCC') for n in top_k_nucs])
        ax3.set_yticks(range(show_top_k))
        ax3.set_yticklabels([f"Pos {idx}: {nuc}" for idx, nuc in zip(top_k_indices, top_k_nucs)])
        ax3.set_xlabel('Importance Score', fontsize=12, fontweight='bold')
        ax3.set_title(f'Top {show_top_k} Most Important Positions', fontsize=14, fontweight='bold')
        ax3.invert_yaxis()
        ax3.grid(axis='x', alpha=0.3)
        
        # 4. æ ¸è‹·é…¸ç±»å‹é‡è¦æ€§åˆ†å¸ƒ
        ax4 = fig.add_subplot(gs[2, 1])
        nuc_importance = {'A': [], 'T': [], 'C': [], 'G': []}
        for i, nuc in enumerate(sequence):
            if nuc.upper() in nuc_importance:
                nuc_importance[nuc.upper()].append(importance_scores[i])
        
        box_data = [nuc_importance[n] for n in ['A', 'T', 'C', 'G']]
        bp = ax4.boxplot(box_data, labels=['A', 'T', 'C', 'G'], patch_artist=True)
        for patch, nuc in zip(bp['boxes'], ['A', 'T', 'C', 'G']):
            patch.set_facecolor(nuc_color_map[nuc])
            patch.set_alpha(0.7)
        ax4.set_ylabel('Importance Score', fontsize=12, fontweight='bold')
        ax4.set_xlabel('Nucleotide Type', fontsize=12, fontweight='bold')
        ax4.set_title('Importance Distribution by Nucleotide Type', fontsize=14, fontweight='bold')
        ax4.grid(axis='y', alpha=0.3)
        
        # 5. æ»‘åŠ¨çª—å£å¹³å‡é‡è¦æ€§
        ax5 = fig.add_subplot(gs[3, 0])
        window_size = 50
        if seq_length >= window_size:
            smoothed = np.convolve(importance_scores, 
                                  np.ones(window_size)/window_size, 
                                  mode='valid')
            ax5.plot(range(len(smoothed)), smoothed, linewidth=2, color='#E74C3C')
            ax5.fill_between(range(len(smoothed)), smoothed, alpha=0.3, color='#E74C3C')
        else:
            ax5.plot(positions, importance_scores, linewidth=2, color='#E74C3C')
        ax5.set_xlabel('Sequence Position', fontsize=12, fontweight='bold')
        ax5.set_ylabel('Smoothed Importance', fontsize=12, fontweight='bold')
        ax5.set_title(f'Smoothed Importance (Window={window_size})', fontsize=14, fontweight='bold')
        ax5.grid(alpha=0.3)
        
        # 6. ç»Ÿè®¡ä¿¡æ¯è¡¨æ ¼
        ax6 = fig.add_subplot(gs[3, 1])
        ax6.axis('off')
        
        stats_data = [
            ['Mean Importance', f'{importance_scores.mean():.4f}'],
            ['Std Importance', f'{importance_scores.std():.4f}'],
            ['Max Importance', f'{importance_scores.max():.4f}'],
            ['Min Importance', f'{importance_scores.min():.4f}'],
            ['Sequence Length', f'{seq_length} bp'],
            ['A Count', f'{sequence.upper().count("A")}'],
            ['T Count', f'{sequence.upper().count("T")}'],
            ['C Count', f'{sequence.upper().count("C")}'],
            ['G Count', f'{sequence.upper().count("G")}'],
            ['GC Content', f'{(sequence.upper().count("G") + sequence.upper().count("C")) / seq_length * 100:.2f}%'],
        ]
        
        table = ax6.table(cellText=stats_data, 
                         colLabels=['Metric', 'Value'],
                         cellLoc='left',
                         loc='center',
                         colWidths=[0.6, 0.4])
        table.auto_set_font_size(False)
        table.set_fontsize(11)
        table.scale(1, 2)
        
        # è®¾ç½®è¡¨æ ¼æ ·å¼
        for i in range(len(stats_data) + 1):
            for j in range(2):
                cell = table[(i, j)]
                if i == 0:
                    cell.set_facecolor('#3498DB')
                    cell.set_text_props(weight='bold', color='white')
                else:
                    cell.set_facecolor('#ECF0F1' if i % 2 == 0 else 'white')
        
        ax6.set_title('Summary Statistics', fontsize=14, fontweight='bold', pad=20)
        
        plt.suptitle(f'Comprehensive Sequence Perturbation Analysis\nSample: {sample_id}', 
                    fontsize=18, fontweight='bold', y=0.995)
        
        if save_dir:
            os.makedirs(save_dir, exist_ok=True)
            save_path = os.path.join(save_dir, f'comprehensive_analysis_{sample_id}.png')
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ’¾ Comprehensive analysis saved to: {save_path}")
        
        plt.show()
        
        return fig
    
    def export_results_to_csv(self, results, sample_id, save_dir=None):
        """å¯¼å‡ºç»“æœåˆ°CSVæ–‡ä»¶"""
        importance_scores = results['importance_scores']
        position_tissue_importance = results['position_tissue_importance']
        sequence = results['sequence']
        
        # åˆ›å»ºDataFrame
        data = {
            'position': range(len(sequence)),
            'nucleotide': list(sequence),
            'importance_score': importance_scores,
        }
        
        # æ·»åŠ æ¯ä¸ªç»„ç»‡çš„é‡è¦æ€§
        for i, tissue in enumerate(self.tissue_names):
            data[f'{tissue}_importance'] = position_tissue_importance[:, i]
        
        df = pd.DataFrame(data)
        
        if save_dir:
            os.makedirs(save_dir, exist_ok=True)
            csv_path = os.path.join(save_dir, f'importance_analysis_{sample_id}.csv')
            df.to_csv(csv_path, index=False)
            print(f"ğŸ’¾ Results exported to: {csv_path}")
        
        return df


def main():
    """ä¸»å‡½æ•°"""
    print("="*80)
    print("ğŸ§¬ Advanced Sequence Perturbation Importance Analysis")
    print("="*80)
    
    # åŠ è½½æ¨¡å‹
    model_path = "/home/sw1136/OmniGenBench/examples/dingling_te/ogb_te_3class_finetuned_epoch_19_seed_42_accuracy_score_0.9900_seed_42_f1_score_0.9900"
    print(f"\nğŸ“¦ Loading model from: {model_path}")
    model = ModelHub.load(model_path)
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = SequencePerturbationAnalyzer(model)
    
    # åŠ è½½æ•°æ®é›†
    print("\nğŸ“Š Loading dataset...")
    model_name_or_path = "yangheng/OmniGenome-52M"
    tokenizer = OmniTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)
    
    datasets = TriClassTEDataset.from_hub(
        dataset_name_or_path=os.path.dirname(__file__),
        tokenizer=tokenizer,
        max_length=512,
        force_padding=False
    )
    
    # é€‰æ‹©æµ‹è¯•æ ·æœ¬
    num_samples = min(3, len(datasets['test'].examples))
    test_samples = datasets['test'].examples[:num_samples]
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    save_dir = "perturbation_analysis_results"
    os.makedirs(save_dir, exist_ok=True)
    
    # å¯¹æ¯ä¸ªæ ·æœ¬è¿›è¡Œåˆ†æ
    for idx, sample in enumerate(test_samples):
        print(f"\n{'='*80}")
        print(f"ğŸ”¬ Analyzing Sample {idx+1}/{num_samples}")
        print(f"   Sample ID: {sample['ID']}")
        print(f"   Sequence Length: {len(sample['sequence'])} bp")
        print(f"{'='*80}")
        
        # è¿›è¡Œå…¨åºåˆ—åˆ†æ
        results = analyzer.analyze_full_sequence(
            sequence=sample['sequence'],
            sample_data=sample,
            step_size=10,  # æ¯10ä¸ªç¢±åŸºæµ‹è¯•ä¸€æ¬¡
            num_perturbations=5,  # æ¯ä¸ªä½ç½®æ‰°åŠ¨5æ¬¡
            perturbation_type='substitution'
        )
        
        # ç»˜åˆ¶ç»¼åˆåˆ†æå›¾
        analyzer.plot_comprehensive_analysis(
            results=results,
            sample_id=sample['ID'],
            save_dir=save_dir,
            show_top_k=20
        )
        
        # å¯¼å‡ºç»“æœåˆ°CSV
        df = analyzer.export_results_to_csv(
            results=results,
            sample_id=sample['ID'],
            save_dir=save_dir
        )
        
        print(f"\nâœ… Sample {idx+1} analysis completed!")
        print(f"   Mean importance: {results['importance_scores'].mean():.4f}")
        print(f"   Max importance: {results['importance_scores'].max():.4f}")
        print(f"   Results saved to: {save_dir}/")
    
    print("\n" + "="*80)
    print("ğŸ‰ All analyses completed!")
    print(f"ğŸ“ Results saved to: {os.path.abspath(save_dir)}/")
    print("="*80)


if __name__ == "__main__":
    main()
