# -*- coding: utf-8 -*-
# file: train_with_kfold.py
# K-Foldäº¤å‰éªŒè¯è®­ç»ƒï¼Œæ›´å‡†ç¡®åœ°è¯„ä¼°æ³›åŒ–èƒ½åŠ›

import torch
import numpy as np
from sklearn.model_selection import KFold
from omnigenbench import (
    ClassificationMetric,
    AccelerateTrainer,
    OmniTokenizer,
)
from triclass_te_improved import TriClassTEDataset, ImprovedOmniModelForTriClassTE

model_name_or_path = "yangheng/OmniGenome-52M"
tokenizer = OmniTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)

print("="*70)
print("ğŸ”„ K-Fold äº¤å‰éªŒè¯è®­ç»ƒ")
print("="*70)

# åŠ è½½æ•°æ®
datasets = TriClassTEDataset.from_hub(
    dataset_name_or_path="examples/dingling_te/",
    tokenizer=tokenizer,
    max_length=512,
    force_padding=False
)

# åˆå¹¶è®­ç»ƒé›†å’ŒéªŒè¯é›†è¿›è¡ŒK-Fold
all_train_data = datasets['train'].examples + datasets['valid'].examples
test_data = datasets['test'].examples

print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
print(f"  æ€»è®­ç»ƒæ•°æ®: {len(all_train_data)}")
print(f"  æµ‹è¯•æ•°æ®: {len(test_data)}")

# K-Foldè®¾ç½®
n_folds = 5
kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)

fold_results = []

print(f"\nğŸ” å¼€å§‹ {n_folds}-Fold äº¤å‰éªŒè¯...")

for fold, (train_idx, val_idx) in enumerate(kf.split(all_train_data), 1):
    print(f"\n{'='*70}")
    print(f"ğŸ“ Fold {fold}/{n_folds}")
    print(f"{'='*70}")
    
    # åˆ›å»ºfoldçš„è®­ç»ƒé›†å’ŒéªŒè¯é›†
    fold_train_data = [all_train_data[i] for i in train_idx]
    fold_val_data = [all_train_data[i] for i in val_idx]
    
    print(f"è®­ç»ƒé›†: {len(fold_train_data)} æ ·æœ¬")
    print(f"éªŒè¯é›†: {len(fold_val_data)} æ ·æœ¬")
    
    # åˆ›å»ºæ•°æ®é›†å¯¹è±¡
    fold_train_dataset = TriClassTEDataset(
        examples=fold_train_data,
        tokenizer=tokenizer,
        max_length=512,
        augment=True
    )
    
    fold_val_dataset = TriClassTEDataset(
        examples=fold_val_data,
        tokenizer=tokenizer,
        max_length=512,
        augment=False
    )
    
    # åˆå§‹åŒ–æ¨¡å‹ï¼ˆæ¯ä¸ªfoldé‡æ–°åˆå§‹åŒ–ï¼‰
    model = ImprovedOmniModelForTriClassTE(
        model_name_or_path,
        tokenizer,
        num_labels=9,
        num_classes=3,
        dropout_rate=0.4,
        freeze_layers=6,
        trust_remote_code=True,
        dataset_class=TriClassTEDataset
    )
    
    # å®šä¹‰metrics
    metric_functions = [
        ClassificationMetric(ignore_y=-100).accuracy_score,
        ClassificationMetric(ignore_y=-100, average='macro').f1_score,
    ]
    
    # è®­ç»ƒå™¨
    trainer = AccelerateTrainer(
        model=model,
        epochs=20,
        learning_rate=1e-5,
        batch_size=8,
        train_dataset=fold_train_dataset,
        eval_dataset=fold_val_dataset,
        test_dataset=None,  # æ¯ä¸ªfoldä¸æµ‹è¯•
        compute_metrics=metric_functions,
        gradient_accumulation_steps=8,
        weight_decay=0.01,
        warmup_steps=100,
        eval_steps=50,
        save_strategy="steps",
        save_steps=50,
        load_best_model_at_end=True,
        metric_for_best_model="accuracy_score",
        greater_is_better=True,
    )
    
    # è®­ç»ƒ
    metrics = trainer.train(
        path_to_save=f"ogb_te_kfold_{fold}",
        dataset_class=TriClassTEDataset
    )
    
    fold_results.append({
        'fold': fold,
        'train_accuracy': metrics.get('train_accuracy_score', 0),
        'val_accuracy': metrics.get('eval_accuracy_score', 0),
        'train_f1': metrics.get('train_f1_score', 0),
        'val_f1': metrics.get('eval_f1_score', 0),
    })
    
    print(f"\nâœ… Fold {fold} å®Œæˆ:")
    print(f"  è®­ç»ƒå‡†ç¡®ç‡: {fold_results[-1]['train_accuracy']:.4f}")
    print(f"  éªŒè¯å‡†ç¡®ç‡: {fold_results[-1]['val_accuracy']:.4f}")
    print(f"  è¿‡æ‹Ÿåˆç¨‹åº¦: {fold_results[-1]['train_accuracy'] - fold_results[-1]['val_accuracy']:.4f}")

# æ±‡æ€»ç»“æœ
print(f"\n{'='*70}")
print("ğŸ“Š K-Fold äº¤å‰éªŒè¯ç»“æœæ±‡æ€»")
print(f"{'='*70}")

train_accs = [r['train_accuracy'] for r in fold_results]
val_accs = [r['val_accuracy'] for r in fold_results]
overfitting_gaps = [t - v for t, v in zip(train_accs, val_accs)]

print(f"\nè®­ç»ƒé›†å‡†ç¡®ç‡: {np.mean(train_accs):.4f} Â± {np.std(train_accs):.4f}")
print(f"éªŒè¯é›†å‡†ç¡®ç‡: {np.mean(val_accs):.4f} Â± {np.std(val_accs):.4f}")
print(f"å¹³å‡è¿‡æ‹Ÿåˆç¨‹åº¦: {np.mean(overfitting_gaps):.4f} Â± {np.std(overfitting_gaps):.4f}")

if np.mean(overfitting_gaps) > 0.20:
    print("\nâŒ è­¦å‘Š: å¹³å‡è¿‡æ‹Ÿåˆç¨‹åº¦ > 0.20ï¼Œæ¨¡å‹æ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼")
    print("å»ºè®®:")
    print("  1. è¿›ä¸€æ­¥å¢åŠ æ­£åˆ™åŒ–ï¼ˆå¢å¤§dropout, weight_decayï¼‰")
    print("  2. å†»ç»“æ›´å¤šå±‚")
    print("  3. å‡å°‘è®­ç»ƒepoch")
    print("  4. æ”¶é›†æ›´å¤šæ•°æ®")
elif np.mean(overfitting_gaps) > 0.10:
    print("\nâš ï¸  æ³¨æ„: æœ‰è½»å¾®è¿‡æ‹Ÿåˆï¼Œå»ºè®®é€‚å½“å¢åŠ æ­£åˆ™åŒ–")
else:
    print("\nâœ… è¿‡æ‹Ÿåˆç¨‹åº¦å¯æ¥å—")

print("\nå„foldè¯¦ç»†ç»“æœ:")
for r in fold_results:
    print(f"  Fold {r['fold']}: Train={r['train_accuracy']:.4f}, "
          f"Val={r['val_accuracy']:.4f}, Gap={r['train_accuracy']-r['val_accuracy']:.4f}")



